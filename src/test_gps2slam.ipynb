{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import video_sync as vs\n",
    "import utm\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_gps_data(jsonfile):\n",
    "    data = vs.object_init(jsonfile)\n",
    "    lat = vs.extract_attribute(data,\"latitude\")\n",
    "    lon = vs.extract_attribute(data,\"longitude\")\n",
    "    acc = vs.extract_attribute(data,\"accuracy\")\n",
    "    time = np.array(vs.extract_attribute(data,\"timestamp\"))/1000\n",
    "    frame = vs.extract_attribute(data, \"frame\")\n",
    "\n",
    "    data_final = np.column_stack((time,frame,lat,lon,acc))\n",
    "    return data_final\n",
    "\n",
    "def extract_slam_data(trajectory):\n",
    "    f = open(trajectory, \"r\")\n",
    "    runs = []\n",
    "    data = []\n",
    "    for i,line in enumerate(f):\n",
    "        if line == \"################################################## \\n\":\n",
    "            if len(data) != 0:\n",
    "                runs.append(np.array(data,dtype='float'))\n",
    "                data = []\n",
    "        else:\n",
    "            l = line.split(\" \")\n",
    "            data.append(l[0:4])\n",
    "    runs.append(np.array(data,dtype='float'))\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_sync(gps_data, slam_runs):\n",
    "    t1 = gps_data[0][0]\n",
    "    t2 = slam_runs[0][0][0]\n",
    "\n",
    "    offset = t2 - t1\n",
    "    for slam_data in slam_runs:\n",
    "        slam_data[:,0] = slam_data[:,0] - offset\n",
    "\n",
    "    return slam_runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_three(gps_data, slam_data):\n",
    "    #Find all the reasonably accurate GPS points (between 0 and 5 meters)    \n",
    "    start = np.searchsorted(gps_data[:,0],slam_data[0][0],'left')\n",
    "    end = np.searchsorted(gps_data[:,0], slam_data[-1][0],'left')\n",
    "    \n",
    "    good_points = np.where(np.logical_and(gps_data[start:end,4] > -1, gps_data[start:end,4]<5))\n",
    "    indices = np.array(random.sample(good_points[0],3)) + start\n",
    "    corsp_slam = []\n",
    "    for t in gps_data[indices][:,0]:\n",
    "        idx = np.searchsorted(slam_data[:,0],t, 'left')\n",
    "        corsp_slam.append(idx)\n",
    "\n",
    "    return gps_data[indices][:,[0,2,3]], slam_data[corsp_slam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_and_combine(gps_data, slam_data):\n",
    "    gps_samples,slam_samples =  sample_three(gps_data, slam_data)\n",
    "    utm_samples = []\n",
    "    for i in xrange(0,3):\n",
    "        u = list(utm.from_latlon(gps_samples[i][1], gps_samples[i][2]))[:2]\n",
    "        u.append(0)\n",
    "        utm_samples.append(u)\n",
    "\n",
    "    A = recover_homogenous_affine_transformation(np.array(slam_samples[:,1:4]),np.array(utm_samples))\n",
    "    \n",
    "    slam_converted = np.zeros((len(slam_data),3))\n",
    "    \n",
    "    for i,obv in enumerate(slam_data):\n",
    "        slam_converted[i][0] = obv[0]\n",
    "        ### One and Three are the two axis aligned to the plane.\n",
    "        utm_conv = transform_pt(obv[1:],A)\n",
    "        gps_conv = utm.to_latlon(utm_conv[0], utm_conv[1],18, 'T')\n",
    "        print gps_conv\n",
    "        slam_converted[i][1:3] = gps_conv\n",
    "\n",
    "    return slam_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slam2gps(jsonfile, frametrajectory):   \n",
    "    gps_data = extract_gps_data(jsonfile)\n",
    "    slam_data = extract_slam_data(frametrajectory)\n",
    "    slam_data = time_sync(slam_data, gps_data)\n",
    "\n",
    "    location_data_final = scale_and_combine(gps_data, slam_data)\n",
    "\n",
    "    return location_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recover_homogenous_affine_transformation(p, p_prime):\n",
    "    '''\n",
    "    Find the unique homogeneous affine transformation that\n",
    "    maps a set of 3 points to another set of 3 points in 3D\n",
    "    space:\n",
    "\n",
    "        p_prime == np.dot(p, R) + t\n",
    "\n",
    "    where `R` is an unknown rotation matrix, `t` is an unknown\n",
    "    translation vector, and `p` and `p_prime` are the original\n",
    "    and transformed set of points stored as row vectors:\n",
    "\n",
    "        p       = np.array((p1,       p2,       p3))\n",
    "        p_prime = np.array((p1_prime, p2_prime, p3_prime))\n",
    "\n",
    "    The result of this function is an augmented 4-by-4\n",
    "    matrix `A` that represents this affine transformation:\n",
    "\n",
    "        np.column_stack((p_prime, (1, 1, 1))) == \\\n",
    "            np.dot(np.column_stack((p, (1, 1, 1))), A)\n",
    "\n",
    "    Source: https://math.stackexchange.com/a/222170 (robjohn)\n",
    "    '''\n",
    "\n",
    "    # construct intermediate matrix\n",
    "    Q       = p[1:]       - p[0]\n",
    "    Q_prime = p_prime[1:] - p_prime[0]\n",
    "\n",
    "    # calculate rotation matrix\n",
    "    R = np.dot(np.linalg.inv(np.row_stack((Q, np.cross(*Q)))),\n",
    "               np.row_stack((Q_prime, np.cross(*Q_prime))))\n",
    "\n",
    "    # calculate translation vector\n",
    "    t = p_prime[0] - np.dot(p[0], R)\n",
    "\n",
    "    # calculate affine transformation matrix\n",
    "    return np.column_stack((np.row_stack((R, t)),\n",
    "                            (0, 0, 0, 1)))\n",
    "\n",
    "\n",
    "\n",
    "def transform_pt(point, trans_mat):\n",
    "    a  = np.array([point[0], point[1], point[2], 1])\n",
    "    ap = np.dot(a, trans_mat)[:3]\n",
    "    return [ap[0], ap[1], ap[2]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_affine_transformation2(p,p_prime):\n",
    "    pad = lambda x: np.hstack([x, np.ones((x.shape[0], 1))])\n",
    "    unpad = lambda x: x[:,:-1]\n",
    "    X = pad(p)\n",
    "    Y = pad(p_prime)\n",
    "\n",
    "    A, res, rank, s = np.linalg.lstsq(X,Y)\n",
    "\n",
    "    return A\n",
    "\n",
    "def transform_pt2(point,trans_mat):\n",
    "    pad = lambda x: np.hstack([x, np.ones((x.shape[0], 1))])\n",
    "    unpad = lambda x: x[:,:-1]\n",
    "\n",
    "    transform = lambda x:unpad(np.dot(pad(x),transmat))\n",
    "\n",
    "    return transform(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gps_data = extract_gps_data(\"/home/carmera/Documents/data/json/cds-1145ca086c7f4f26-20170608-0742.json\")\n",
    "slam_runs = extract_slam_data(\"/home/carmera/KeyFrame-test.txt\")\n",
    "slam_runs = time_sync(gps_data, slam_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, p_prime = sample_three(gps_data, slam_runs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = find_affine_transformation2(p,p_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00740123e+00  -1.13756044e-05  -3.37236403e-05   1.26072247e-04\n",
      "    6.71148420e-10]\n",
      " [  1.05093163e+05  -4.69907758e+01  -1.39306134e+02   5.20781585e+02\n",
      "    6.26331263e-05]\n",
      " [  2.07701738e+05  -2.56160438e+02  -7.59398337e+02   2.83893225e+03\n",
      "    9.74696824e-05]\n",
      " [  2.68269324e+01  -2.79110516e-02  -8.27434813e-02   3.09327958e-01\n",
      "    1.34232458e-08]]\n"
     ]
    }
   ],
   "source": [
    "print A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.06e+02,   7.35e+02,   1.69e+04,   0.00e+00],\n",
       "       [ -4.12e+03,   2.86e+04,  -4.49e+02,   0.00e+00],\n",
       "       [ -1.77e+02,   1.22e+03,   3.27e+02,   0.00e+00],\n",
       "       [  5.89e+05,   4.51e+06,  -1.51e+02,   1.00e+00]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
